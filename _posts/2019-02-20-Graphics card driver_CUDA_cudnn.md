---
layout: post
title: 显卡驱动、CUDA和cudnn的关系
subtitle: 系统相关名词解释
tags: [Computer System]
comments: true
---

<!-- ## 显卡驱动、CUDA和cudnn的关系 -->

### 一、显卡驱动、CUDA、cuDNN介绍

**NVIDIA的显卡驱动程序（NVIDIA Game Ready）**，显卡驱动分内核态和用户态两部分，内核态驱动只管将用户态驱动发过来的命令和数据准备好，通知GPU来拿，利用环形fifo来下发命令和数据指针，并追踪命令的完成状态。用户态部分，负责对shader程序的编译，编译成GPU的二进制代码指令。OS提供的D3D,OpenGL等函数库，屏蔽底层不同显卡的差异。上层程序比如游戏，在准备好对应的模型、贴图纹理、着色器程序等数据之后，调用统一的D3D/OpenGL接口发起绘制请求，D3D则调用显卡用户态驱动提供的回调函数将对应的数据传递给后者，后者进行运行时编译生成底层代码，然后传递给内核态驱动，内核态驱动将命令和数据发送给GPU。至于GPU怎么算的，那就是完全另外一回事了。

当我们使用一台电脑的时候默认的已经安装了NVIDIA的显卡驱动，因为没有显卡驱动根本用不了显卡，但是这个时候我们是没有CUDA可以用的，但我们可以更新我们的驱动，，在这个里面可以根据自己的显卡类型选择最新的驱动程序。显卡驱动程序大小约为500多M。

**CUDA的本质是一个工具包（ToolKit）**。CUDA是NVIDIA推出的用于自家GPU的并行计算框架，也就是说CUDA只能在NVIDIA的GPU上运行，而且只有当要解决的计算问题是可以大量并行计算的时候才能发挥CUDA的作用。CUDA就是通用计算，游戏让GPU算的是一堆像素的颜色，而GPU完全可以算其他任何运算，比如大数据量矩阵乘法等。同样，程序准备好对应的数组，以及让GPU如何算这些数组的描述结构（比如让GPU内部开多少个线程来算，怎么算，之类），这些数据和描述，都要调用CUDA库提供的函数来传递给CUDA，CUDA再调用显卡用户态驱动对CUDA程序进行编译，后者再调用内核态驱动将命令以及编译好的程序数据传送给GPU。CUDA，就是相当于一个专门与通用程序而不是图形程序对接的库，那么它的角色和地位与D3D/OpenGL在系统架构层次中是齐平的。

CUDA ToolKit的安装：[CUDA ToolKit下载地址](https://developer.nvidia.com/cuda-downloads)

我们可以选择两种安装方式，一种是在线安装（我还没用过），一种离线安装（我采用的）即本地安装。当我们选择离线安装，当我们选定相对应的版本之后，下载的时候发现这个地方的文件大小大概在2G左右，Linux系统下面我们选择runfile(local) 完整安装包从本地安装，或者是选择windows的本地安装。CUDA Toolkit本地安装包时内含特定版本Nvidia显卡驱动的，所以只选择下载CUDA Toolkit就足够了，如果想安装其他版本的显卡驱动就下载相应版本即可。

所以，NVIDIA的显卡驱动程序和CUDA完全是两个不同的概念，NVIDIA显卡驱动和CUDA工具包本身是不具有捆绑关系的，也不是一一对应的关系，只不过是离线安装的CUDA工具包会默认携带与之匹配的最新的驱动程序，可以根据个人需要以及各版本之间的协调性进行选择。

注意事项：NVIDIA的显卡驱动器与CUDA并不是一一对应的，CUDA本质上只是一个工具包，可以在同一个设备上安装很多个不同版本的CUDA工具包，比如我的电脑上装了 CUDA 9.0、CUDA 9.2、CUDA 10.0三个版本。一般情况下，我只需要安装最新版本的显卡驱动，然后根据自己的选择选择不同CUDA工具包就可以了，但是由于使用离线的CUDA总是会捆绑CUDA和驱动程序，所以在使用多个CUDA的时候就不要选择离线安装的CUDA了，否则每次都会安装不同的显卡驱动，这不太好，可以直接安装一个最新版的显卡驱动，然后在线安装不同版本的CUDA即可。

**cuDNN 是针对深度神经网络的加速库**，是一个SDK，注意，它跟我们的CUDA没有一一对应的关系，即每一个版本的CUDA可能有好几个版本的cuDNN与之对应，但一般有一个最新版本的cuDNN版本与CUDA对应更好，只需要将cudnn压缩包中的库文件复制到CUDA工具包相应的文件夹中，即可达到提升计算机并行运算性能的目的。

cuDNN的安装：[cuDNN下载地址](https://developer.nvidia.com/rdp/cudnn-download)

对于CUDA 工具包附带的 CUPTI，即CUDA Profiling Tools Interface (CUPTI)。在CUDA分析工具接口（CUPTI）能够分析和跟踪靶向CUDA应用程序的工具的创建。CUPTI提供以下API：Activity API，Callback API，事件API，Metric API，和Profiler API。使用这些API，您可以开发分析工具，深入了解CUDA应用程序的CPU和GPU行为。CUPTI作为CUDA支持的所有平台上的动态库提供。请参阅CUPTI文档。

有一个比喻能够更形象的说明CUDA、cuDNN两者的关系：CUDA看作是一个工作台，上面配有很多工具，如锤子、螺丝刀等。cuDNN是基于CUDA的深度学习GPU加速库，有了它才能在GPU上完成深度学习的计算。它就相当于工作的工具，比如它就是个扳手。但是CUDA这个工作台买来的时候，并没有送扳手。想要在CUDA上运行深度神经网络，就要安装cuDNN，就像你想要拧个螺帽就要把扳手买回来。这样才能使GPU进行深度神经网络的工作，工作速度相较CPU快很多。

### 二、安装以及版本选择说明

#### 1、驱动安装

首先安装NVIDIA显卡驱动，[NVIDIA显卡驱动](https://www.nvidia.com/Download/index.aspx?lang=cn)，然后重启结束显卡驱动安装，显卡安装成功后鼠标右键—>点击NVIDIA控制面板—>`系统信息`

在`显示`一栏中，查看安装好的显卡驱动版本，我的版本是432.00，在`组件`一栏中，可以看到 

|   文件名   |   文件版本    |          产品名称           |
| :--------: | :-----------: | :-------------------------: |
| NVCUDA.DLL | 26.21.12..... | NVIDIA CUDA 10.1.120 driver |

网上有一部分资料认为产品名称中的`10.1.120`才是安装好的显卡驱动对应的CUDA版本号，不知依据出自何处。如果按照网上的步骤，我应该选择CUDA`10.1.120`，但尴尬的是，在我发布这篇博客的时候NVIDIA还没有发布这么高的版本，所以不科学。

我对CUDA `10.1.120`的理解是，当前我安装的显卡驱动最高能支持的CUDA版本是`10.1.120`，这可能是NVIDIA在写驱动程序的时候规划好的。（对于CUDA的版本选择让我困惑了一段时间，通过翻阅官方文档消除了疑惑，如果想更深一步了解，下一步CUDA安装中我有详细的举例说明）

#### 2、CUDA安装

CUDA安装官网描述：运行CUDA应用程序的两个必要条件是
（1）系统至少拥有一个支持CUDA编程的GPU硬件；
（2）能够兼容CUDA的驱动程序版本。
通过参考[官网文档](<https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html>)我对下图表格的理解：
（1）NVDIA发布的每一个CUDA工具包都有一个最低版本的显卡驱动限制，比如下表中是目前最新版本的CUDA 10.2.89，Windows下其支持的显卡驱动最低版本是441.22，也就是说低于441.22的显卡驱动都无法安装CUDA 10.2.89。
（2）显卡驱动是向后兼容的，新的版本兼容旧的版本。
（3）对于指定的一个CUDA工具包仍然适用于后续NVIDIA发布的更高版本驱动。举例说明：如果我的显卡驱动版本是445.75>=441.22，那么意味着目前我安装的显卡驱动都能与表中的CUDA任何一个版本兼容。假如你显卡驱动版本是400.36>= 398.26，但是<411.31，就只能兼容CUDA 9.2 (9.2.148 Update 1)及以下（包含9.2）CUDA版本，以上则不能。

|                   CUDA Toolkit                    | Linux x86_64 Driver Version | Windows x86_64 Driver Version |
| :-----------------------------------------------: | :-------------------------: | :---------------------------: |
|                   CUDA 10.2.89                    |          >= 440.33          |           >= 441.22           |
| CUDA 10.1 (10.1.105 general release, and updates) |          >= 418.39          |           >= 418.96           |
|                   CUDA 10.0.130                   |          >= 410.48          |           >= 411.31           |
|            CUDA 9.2 (9.2.148 Update 1)            |          >= 396.37          |           >= 398.26           |
|                 CUDA 9.2 (9.2.88)                 |          >= 396.26          |           >= 397.44           |
|                 CUDA 9.1 (9.1.85)                 |          >= 390.46          |           >= 391.29           |
|                 CUDA 9.0 (9.0.76)                 |          >= 384.81          |           >= 385.54           |
|               CUDA 8.0 (8.0.61 GA2)               |          >= 375.26          |           >= 376.51           |
|                 CUDA 8.0 (8.0.44)                 |          >= 367.48          |           >= 369.30           |
|                 CUDA 7.5 (7.5.16)                 |          >= 352.31          |           >= 353.66           |
|                 CUDA 7.0 (7.0.28)                 |          >= 346.46          |           >= 347.62           |

至此，明确了显卡驱动和CUDA的兼容关系，然后根据你要配置的深度学习框架来最终选择CUDA版本。



### 注意：

在使用`nvidia-smi`命令后，显示GPU状态的表头如下：

```bash
$ nvidia-smi
Tue May 19 12:01:17 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 432.00       Driver Version: 432.00       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN Xp           WDDM  | 00000000:01:00.0  On |                  N/A |
| 24%   42C    P8    19W / 250W |   1510MiB / 12288MiB |      2%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
```

但是使用NVCC -V命令后，显示如下：

```bash
$ NVCC -V
NVCC: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2017 NVIDIA Corporation
Built on Fri_Sep__1_21:08:32_Central_Daylight_Time_2017
Cuda compilation tools, release 9.0, V9.0.176
```

所以关于命令`nvidia-smi`和`NVCC -V`所显示CUDA version不相同的问题，我的个人理解是：

> `NVCC -V`命令显示的是本机上现在存在的真实的CUDA toolkit组件版本，而`nvidia-smi`命令显示的是类似于前文中所述，当前安装的显卡驱动所能支持的最高的CUDA版本是`10.1`（`10.1.120`）